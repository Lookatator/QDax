{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-iBHfWH0MmR"
   },
   "source": [
    "## Example of how to use the QDax library to run MAP-Elites on brax environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "wmq6DNdm0Af0"
   },
   "outputs": [],
   "source": [
    "#@title Installs and Imports\n",
    "!pip install ipympl |tail -n 1\n",
    "# %matplotlib widget\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "try:\n",
    "    import brax\n",
    "except:\n",
    "  !pip install git+https://github.com/google/brax.git@main |tail -n 1\n",
    "  import brax\n",
    "\n",
    "from brax.experimental.composer import register_default_components\n",
    "\n",
    "try:\n",
    "    import qdax\n",
    "except:\n",
    "    !pip install --no-deps git+https://github.com/adaptive-intelligent-robotics/QDax@2-instadeep-new-structure-suggestion |tail -n 1\n",
    "    import qdax\n",
    "\n",
    "from qdax.algorithms.map_elites import MAPElites, compute_cvt_centroids\n",
    "from qdax import brax_envs\n",
    "from qdax.utils.mdp_utils import scoring_function, Transition\n",
    "from qdax.utils.networks import MLP\n",
    "from qdax.emitters.mutation_operators import isoline_crossover_function\n",
    "from qdax.emitters.emitters import mixing_emitter\n",
    "from qdax.utils.plotting import plot_2d_map_elites_grid\n",
    "\n",
    "\n",
    "\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "  from jax.tools import colab_tpu\n",
    "  colab_tpu.setup_tpu()\n",
    "\n",
    "\n",
    "QD_PARAMS = dict()\n",
    "\n",
    "register_default_components()\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Rri1PhiG0SXY"
   },
   "outputs": [],
   "source": [
    "#@title QD Training Definitions Fields\n",
    "#@markdown ---\n",
    "batch_size = 1024 #@param {type:\"number\"}\n",
    "env_name = 'ant_omni'#@param['ant', 'hopper', 'walker', 'halfcheetah', 'humanoid', 'ant_omni', 'humanoid_omni']\n",
    "episode_length = 100 #@param {type:\"integer\"}\n",
    "num_iterations = 100 #@param {type:\"integer\"}\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "policy_hidden_layer_sizes = [64, 64] #@param {type:\"raw\"}\n",
    "num_init_cvt_samples = 50000 #@param {type:\"integer\"}\n",
    "num_centroids = 10000 #@param {type:\"integer\"}\n",
    "min_bd = -15.0 #@param {type:\"number\"}\n",
    "max_bd = 15.0 #@param {type:\"number\"}\n",
    "#@markdown ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZUjFmy72oSf"
   },
   "outputs": [],
   "source": [
    "# Init environment\n",
    "env = brax_envs.create(env_name)\n",
    "\n",
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Init policy network\n",
    "policy_layer_sizes = policy_hidden_layer_sizes + [env.action_size]\n",
    "policy_network = MLP(\n",
    "    layer_sizes=policy_layer_sizes,\n",
    "    kernel_init=jax.nn.initializers.lecun_uniform(),\n",
    "    kernel_init_final=jax.nn.initializers.uniform(1e-3),\n",
    "    final_activation=jnp.tanh,\n",
    ")\n",
    "\n",
    "# Init population of controllers\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jax.random.split(subkey, num=batch_size)\n",
    "fake_batch = jnp.zeros(shape=(batch_size, env.observation_size))\n",
    "init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "\n",
    "\n",
    "# Create the initial environment states\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "keys = jnp.repeat(jnp.expand_dims(subkey, axis=0), repeats=batch_size, axis=0)\n",
    "reset_fn = jax.jit(jax.vmap(env.reset))\n",
    "init_states = reset_fn(keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2o9tA-Gjan0"
   },
   "outputs": [],
   "source": [
    "# Define the fonction to play a step with the policy in the environment\n",
    "def play_step_fn(\n",
    "  env_state,\n",
    "  policy_params,\n",
    "  random_key,\n",
    "):\n",
    "  \"\"\"\n",
    "  Play an environment step and return the updated state and the transition.\n",
    "  \"\"\"\n",
    "\n",
    "  actions = policy_network.apply(policy_params, env_state.obs)\n",
    "  next_state = env.step(env_state, actions)\n",
    "\n",
    "  transition = Transition(\n",
    "      obs=env_state.obs,\n",
    "      next_obs=next_state.obs,\n",
    "      rewards=next_state.reward,\n",
    "      dones=next_state.done,\n",
    "      actions=actions,\n",
    "      state_desc=env_state.info[\"state_descriptor\"],\n",
    "  )\n",
    "\n",
    "  return next_state, policy_params, random_key, transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XSA_hfZGliT"
   },
   "outputs": [],
   "source": [
    "# Prepare the scoring function\n",
    "random_key, subkey = jax.random.split(random_key)\n",
    "bd_extraction_fn = brax_envs.behavior_descriptor_extractor[env_name]\n",
    "scoring_fn = functools.partial(\n",
    "    scoring_function,\n",
    "    init_states=init_states,\n",
    "    episode_length=episode_length,\n",
    "    random_key=random_key,\n",
    "    play_step_fn=play_step_fn,\n",
    "    behavior_descriptor_extractor=bd_extraction_fn,\n",
    ")\n",
    "\n",
    "# Define emitter\n",
    "crossover_fn = functools.partial(\n",
    "    isoline_crossover_function, iso_sigma=0.05, line_sigma=0.1\n",
    ")\n",
    "emitter_mixing_fn = functools.partial(\n",
    "    mixing_emitter, \n",
    "    mutation_fn=None, \n",
    "    crossover_fn=crossover_fn, \n",
    "    crossover_percentage=1.0, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Note that the mixing emitter does not need an internal state\n",
    "# but the implementation of MAP-Elites is general and assume that emitter take\n",
    "# and return emitter states. Thus, here we add a non_usued one just to make\n",
    "# the signatures fit.\n",
    "def emitter_fn(repertoire, emitter_state, random_key):\n",
    "    genotypes, random_key = emitter_mixing_fn(\n",
    "        repertoire,\n",
    "        random_key,\n",
    "    )\n",
    "    return genotypes, emitter_state, random_key\n",
    "\n",
    "# Get minimum reward value to make sure qd_score are positive\n",
    "reward_offset = brax_envs.reward_offset[env_name]\n",
    "\n",
    "# Define a metrics function\n",
    "def metrics_fn(repertoire):\n",
    "\n",
    "    # Get metrics\n",
    "    grid_empty = repertoire.fitnesses == -jnp.inf\n",
    "    qd_score = jnp.sum(repertoire.fitnesses, where=~grid_empty)\n",
    "    # Add offset for positive qd_score\n",
    "    qd_score += reward_offset * episode_length * jnp.sum(1.0 - grid_empty)\n",
    "    coverage = 100 * jnp.mean(1.0 - grid_empty)\n",
    "    max_fitness = jnp.max(repertoire.fitnesses)\n",
    "\n",
    "    return {\n",
    "        \"qd_score\": qd_score, \"max_fitness\": max_fitness, \"coverage\": coverage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ9qXib2JDyC"
   },
   "outputs": [],
   "source": [
    "# Instantiate MAP-Elites\n",
    "map_elites = MAPElites(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter_function=emitter_fn,\n",
    "    metrics_function=metrics_fn,\n",
    ")\n",
    "\n",
    "# Compute the centroids\n",
    "centroids = compute_cvt_centroids(\n",
    "    num_descriptors=env.behavior_descriptor_length,\n",
    "    num_init_cvt_samples=num_init_cvt_samples,\n",
    "    num_centroids=num_centroids,\n",
    "    minval=min_bd,\n",
    "    maxval=max_bd,\n",
    ")\n",
    "\n",
    "# Compute initial repertoire\n",
    "repertoire = map_elites.init_fn(init_variables, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3J9UjN3LWnh"
   },
   "outputs": [],
   "source": [
    "# Prepare scan over map_elites update to perform several iterations at a time\n",
    "@jax.jit\n",
    "def update_scan_fn(carry, unused):\n",
    "    # iterate over grid\n",
    "    repertoire, random_key = carry\n",
    "    (repertoire, _, metrics, random_key,) = map_elites.update_fn(\n",
    "        repertoire,\n",
    "        None,\n",
    "        random_key,\n",
    "    )\n",
    "\n",
    "    return (repertoire, random_key), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-PYvcmILwG6"
   },
   "outputs": [],
   "source": [
    "# Run the algorithm\n",
    "(repertoire, random_key,), metrics = jax.lax.scan(\n",
    "    update_scan_fn,\n",
    "    (repertoire, random_key),\n",
    "    (),\n",
    "    length=num_iterations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "tJ7w7UCWnDID",
    "outputId": "6df34559-3ac8-4850-c11e-60565bae8be4"
   },
   "outputs": [],
   "source": [
    "#@title Visualization\n",
    "\n",
    "# Customize matplotlib params\n",
    "font_size = 16\n",
    "params = {\n",
    "    \"axes.labelsize\": font_size,\n",
    "    \"axes.titlesize\": font_size,\n",
    "    \"legend.fontsize\": font_size,\n",
    "    \"xtick.labelsize\": font_size,\n",
    "    \"ytick.labelsize\": font_size,\n",
    "    \"text.usetex\": False,\n",
    "    \"axes.titlepad\": 10,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "# Visualize the training evolution and final repertoire\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(40,10))\n",
    "\n",
    "env_steps = jnp.arange(num_iterations) * episode_length * batch_size\n",
    "\n",
    "axes[0].plot(env_steps, metrics['coverage'])\n",
    "axes[0].set_xlabel('Environment steps')\n",
    "axes[0].set_ylabel('Coverage in %')\n",
    "axes[0].set_title('Coverage evolution during training')\n",
    "axes[0].set_aspect(0.95/axes[0].get_data_ratio(), adjustable='box')\n",
    "\n",
    "axes[1].plot(env_steps, metrics['max_fitness'])\n",
    "axes[1].set_xlabel('Environment steps')\n",
    "axes[1].set_ylabel('Maximum fitness')\n",
    "axes[1].set_title('Maximum fitness evolution during training')\n",
    "axes[1].set_aspect(0.95/axes[1].get_data_ratio(), adjustable='box')\n",
    "\n",
    "axes[2].plot(env_steps, metrics['qd_score'])\n",
    "axes[2].set_xlabel('Environment steps')\n",
    "axes[2].set_ylabel('QD Score')\n",
    "axes[2].set_title('QD Score evolution during training')\n",
    "axes[2].set_aspect(0.95/axes[2].get_data_ratio(), adjustable='box')\n",
    "\n",
    "plot_2d_map_elites_grid(\n",
    "    centroids=centroids,\n",
    "    grid_fitness=repertoire.fitnesses,\n",
    "    minval=min_bd,\n",
    "    maxval=max_bd,\n",
    "    grid_descriptors=repertoire.descriptors,\n",
    "    ax=axes[3],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "qdax_suggestion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
